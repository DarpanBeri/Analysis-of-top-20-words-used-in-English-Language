{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pollard Analysis\n",
    "\n",
    "This notebook contains code which will:\n",
    "* Download and install the Brown corpus.\n",
    "* Analyse and print out the number of word types that account for a third of all word tokens in Brown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downloading and installing the Brown Corpus.\n",
    "\n",
    "* After running the code in the cell below, a window will open.\n",
    "* Choose the tab labeled Corpora, select Brown, and click the download button at the bottom of the window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading and installing the Brown corpus\n",
    "import nltk\n",
    "nltk.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should have Brown Corpus installed in your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the necessary libraries\n",
    "import nltk # Natural language toolkit\n",
    "from nltk.corpus import brown # Importing the Coprus\n",
    "from collections import defaultdict, Counter # Libraries needed for data analysis and manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1161192\n"
     ]
    }
   ],
   "source": [
    "bw = brown.words()\n",
    "size = len(bw)\n",
    "print(size) # Lets see the numbers of words we are working with"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<FreqDist with 49815 samples and 1161192 outcomes>\n"
     ]
    }
   ],
   "source": [
    "freqDist = nltk.FreqDist([w.lower() for w in bw]) # Lowercasing all words to ignore special cases\n",
    "print(freqDist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sizeThird = float(size)/3\n",
    "wordTokens = 0\n",
    "wordTypes = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for (word,count) in freqDist.most_common(20):\n",
    "    if wordTokens < sizeThird:\n",
    "        wordTypes += 1\n",
    "        wordTokens += count\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 16 wordtypes for a third of all word tokens in a balanced english corpus.\n"
     ]
    }
   ],
   "source": [
    "print(\"There are \"+str(wordTypes)+\" wordtypes for a third of all word tokens in a balanced english corpus.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q. How many word types account for a third of all word tokens in Brown?\n",
    "### Ans. There are 16 word types for a third of all word tokens in Brown."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q What do you conclude about the statistic cited in Vicky Pollardâ€™s article? \n",
    "### Ans. The Vicky Pollard's article claims that having only 20 word types for a third of all word tokens shows poor verbal skills. But, checking for the number of word types accounting for a third of all word tokens in Brown shows that Brown only has 16 word types, a number lower than even Vicky Pollard's! I believe that the BBC article was part of the panic caused by the new and tech-savvy generation. As with every new generation, the current generation will critique them and find examples to support their critique."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
